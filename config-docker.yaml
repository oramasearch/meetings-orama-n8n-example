http:
  host: 0.0.0.0
  port: 8080
  allow_cors: true
  with_prometheus: true

log:
  file_path: "./log.log"

writer_side:
  output:
    type: in-memory

  hooks:
    select_embeddings_properties:
      check_interval: 60s
      max_idle_time: 20s
      instances_count_per_code: 3
      queue_capacity: 100
      max_execution_time: 1s
      max_startup_time: 100ms

  master_api_key: ${ORAMA_CORE_MASTER_API_KEY}
  config:
    data_dir: ./.data/writer
    embedding_queue_limit: 50000
    insert_batch_commit_size: 50000000
    default_embedding_model: BGESmall
    javascript_queue_limit: 500000
    commit_interval: 1m

reader_side:
  input:
    type: in-memory

  config:
    data_dir: ./.data/reader
    insert_batch_commit_size: 50000000
    commit_interval: 1m

ai_server:
  scheme: http
  host: python-ai-server
  port: 50051
  api_key: ""
  max_connections: 15
  total_threads: 12

  embeddings:
    default_model_group: small
    dynamically_load_models: false
    execution_providers:
      - CPUExecutionProvider
    total_threads: 8
    automatic_embeddings_selector:
      model: gpt-4.1
      provider: openai

  llm:
    local: false
    host: "https://api.openai.com/v1"
    model: gpt-4.1
    api_key: ${OPENAI_API_KEY}

  remote_llms:
    - provider: openai
      api_key: ${OPENAI_API_KEY}
      default_model: gpt-4.1
